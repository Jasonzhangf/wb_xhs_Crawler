# 炸裂！AI科研神器CycleResearcher

今天来聊聊一篇超酷的AI科研论文，用大模型实现科研全流程自动化！
1. 核心创新点
🌟双模型闭环打工：搞了个CycleResearcher负责写论文（从读文献、想点子到设计实验全包干），搭配CycleReviewer当“虚拟审稿人”，写完直接模拟专家审稿给反馈，俩模型互相打工形成“科研-审稿-优化”闭环，再也不是单打独斗啦！
🌟手把手教AI学科研：专门搞了俩超全数据集——Review-5k和Research-14k，像老师带学生一样，让AI从海量论文里学怎么写稿、怎么审稿，再也不是“野生AI”啦！
🌟给AI上紧箍咒：怕AI乱搞学术？安排了Fast-DetectGPT检测工具，能95%+准确识别AI生成内容，还要求所有AI辅助论文必须明说“我用了工具”，主打一个透明科研！
2. 技术亮点
🌟像打游戏刷副本一样迭代：CycleResearcher每次写完论文，CycleReviewer就打分，挑出“高分作业”和“低分作业”对比学习，越练越强，有点像游戏里刷装备升级的感觉～
🌟审稿模拟超真实：CycleReviewer能学不同审稿人风格，有的严有的松，最后综合打分，连“微弱接受”“强烈拒绝”这种细节都能模拟，再也不是一刀切的评分啦！
🌟从小白到专家的成长路：用 Mistral、Qwen 等开源大模型打底，从12B到123B参数规模一路升级，小模型学基础，大模型搞复杂推理，妥妥的AI养成记！
3. 实验效果
🌟审稿能力超厉害：CycleReviewer打分比人类审稿人更准，MAE（误差）比真人低26.89%，连GPT-4o这些闭源模型都被甩在后面，以后审稿说不定能当人类助手啦！
🌟生成论文接近真人水平：CycleResearcher写的论文在模拟审稿中拿了5.36分，比人类预印本的5.24分还高，虽然离Accepted的5.69分还有进步空间，但已经能打了！
🌟火眼金睛辨AI：检测工具识别AI生成论文准确率超98%，以后想偷偷用AI写稿不声明？没门！
论文：CYCLERESEARCHER: IMPROVING AUTOMATED RESEARCH VIA AUTOMATED REVIEW
你们觉得这种AI辅助科研是解放生产力，还是会带来学术诚信问题呀？评论区聊聊～ 😉
🌟欢迎投稿🌟 ﻿#大模型

## 评论

* 想问下uu，这种风格的ai论文总结是怎么做的，是先写初稿再用ai润色吗

[原文链接](https://www.xiaohongshu.com/explore/67ea4ef2000000001c0140ff?xsec_token=ABZRsjvM01ubq2KaOEuJrLOp8q1XByXaIfjiVonBdqaus=&xsec_source=pc_search&source=web_explore_feed)

---

# 大模型微调全解析｜12张图带你系统了解！

🔥 第一张｜大模型微调详解
大模型微调需要的显存（VRAM）有多大？不同规模（3B到11B）在QLoRA和LoRA微调下的最低显存需求一览，还有如何设置batch size来避免OOM问题！
💬 第二张｜理解LLM微调
微调不仅能更新知识，还能定制模型的语气、回答风格、提升特定任务的准确性。应用领域涵盖金融、客服、法律文档分析！
🔍 第三张｜微调 vs RAG：全面对比
微调可以做到RAG的几乎所有事情，但RAG无法取代微调！尤其是在嵌入知识、理解上下文、处理专业任务方面，微调优势巨大。
✨ 第四张｜微调的关键优势
总结微调的5大王牌能力：
1）任务专精、2）独立于检索系统、3）快速响应、4）自定义行为、5）更可靠的性能保障！
⚡ 第五张｜常见误解澄清
误解1：微调不会引入新知识？错！
误解2：RAG一定更好？错！
误解3：微调很贵？也错！QLoRA低成本微调了解一下！
🎯 第六张｜LoRA vs QLoRA：哪个更好？
对比两种微调方法：QLoRA显存更低、计算更省，精准度接近LoRA，性价比超高！👉 最推荐大多数人使用QLoRA！
🔍 第七张｜选择哪个模型？
选择模型时要看：任务类型（视觉、代码）、许可要求、显存与计算资源。并建议使用最新模型，比如Llama 3.3（2025年领先）。
📈 第八张｜指令模型 or 基础模型？
数据量大？选基础模型！数据量小？选指令模型！详细解释不同数据规模下如何做选择，让你的微调更高效！
🛠 第九张｜LoRA参数百科（基础参数）
学习率（Learning Rate）和训练轮次（Epochs）是微调成败的关键，教你如何设置合理范围，避免过拟合和欠拟合。
🧠 第十张｜LoRA参数百科（高级参数）
进阶设置来了！LoRA Rank、Alpha、Dropout、Batch Size等全解释，附带推荐参数区间，实操直接套用！
⚡ 第十一张｜避免过拟合与欠拟合
如果模型记住了训练数据就是过拟合，如果学不懂就是欠拟合！这里教你怎么通过学习率、轮次、Dropout等技巧应对。
🔍 第十二张｜微调没有单一最优方法
不同场景不同最佳实践！讲清楚各个模块（q_proj、k_proj、v_proj、o_proj、gate_proj等）在微调过程中的作用，帮你理解底层机制。
	
﻿#大模型﻿ ﻿#大模型微调﻿ ﻿#大模型训练﻿ ﻿#大模型应用﻿ ﻿#人工智能﻿ ﻿#深度学习

## 评论

* 更大模型没有列出来
* 放不下图，以后更新

[原文链接](https://www.xiaohongshu.com/explore/680d005a000000001d023d70?xsec_token=ABpeqIcNbq_yCKtwPcvU99BZk4Xez4Q3rtJvLQebJL-bQ=&xsec_source=pc_search&source=web_explore_feed)

---

# 老铁厂OneRec👍端对端推荐大模型方案来了

🌊大模型的风往搜推广业界吹了好久，但现有的工作往往被禁锢在两种枷锁中：
1️⃣学术玩具：纯在学术离线环境下验证，不能在现实工业环境中超过【召回-粗排-精排-混排】这样的传统级联推荐系统；
2️⃣特征提取器：生成式模型最终的作用只是传统推荐系统提取特征，不能端对端地真正发挥生成式模型的威力。
	
🔥上周末老铁厂周国睿老师的团队发布了OneRec，真正的一阶段端对端生成式推荐模型！完全丢掉【召回-粗排-精排】的漏斗，性能还更胜一筹
	
📚搜推广算法打工人必须关注一波：OneRec: Unifying Retrieve and Rank with Generative Recommender and Iterative Preference Alignment
	
✌️细读前点个免费的关注和收藏，北大小哥Sam每天带你读LLM和推荐广告前沿论文，侃算法岗面经&成长经验
	
🌸咱们按【模型结构】、【数据组织】、【训练方法】、【实验评测】四块来高效学习
	
1️⃣模型结构：如p2所示，类似T5的encoder-decoder，输入用户历史行为序列，输出用户接下来要看的session序列。和T5的主要不同是，decoder侧的FFN使用了SparseMoE来堆叠参数量。
	
2️⃣训练数据的组织：
1. 每个item(视频)用多模态embedding 层次化K-means聚类后的簇ID表示；
2. 输入为用户某时刻的历史交互序列（观看/收藏/分享/关注up主的视频），输出为接下来要推给用户的一个session（5-10个视频），只选取观看视频数据>=5 & 总观看时间＞一定门槛 & 有分享/喜欢/关注等互动行为的 【高质量】session作为训练数据的输出
	
3️⃣训练方法：
阶段1：常规的encoder-decoder序列生成；
阶段2：类似LLM DPO的RL偏好对齐：
A. 先训一个输入<历史序列，观看session>，输出<观看时间，点击率，关注率，喜欢率>奖励信号的reward model
B. 再用这个reward model造DPO数据：用encoder-decoder模型beam search出若干个目标session序列，选择其中reward最高的为y_win，最低的为y_lose，进行DPO训练
	
4️⃣实验效果方面，老规矩，只看线上AB(p3)：
A. 相比线上的多阶段base，0.1B的基础版本OneRec带来总时长+0.57%/平均时长+4.26%
B. 参数量增加到1B后进一步提升，总时长+0.57%/平均时长+1.21%//平均时长+5.01%
C. 增加DPO后，总时长+0.57%/平均时长+1.68%//平均时长+6.56%
	
#大模型 #算法岗 #大厂 #推荐算法 #春招 #deepseek #慢脚 #北大 #深度学习与神经网络

## 评论

* 别看了，没落地
* 真的吗？
* item2token用聚类，生成了token要怎么回到item呢
* 候选池计算一个点积相似度？
* 听说没上线诶
* 文章没提infra方面的工作 可能时延还是瓶颈？
* 时延怎么样
* 文章没提infra方面的工作，评论区有朋友说没有全量，可能时延还是瓶颈？
* 稍微是沾点边工作的都应该知道 目前这阶段不可能  100ms 对于llm来说 序列的cache还没查完呢
* 为什么使用encoder- decoder而不是decoder-only，文章似乎没讨论也没做实验
* 吹牛的工作
* 数据咋保持更新呢，不会一直有新的视频id产生么
* 快手关注的最核心的指标就是时长吗，看结尾提到了其他指标可能有下降
* 时长在抖音是最不值钱的指标，还活跃天或者收入都是值得的
* @薯条我喜欢堂食 介么牛？
* 内部学习下

[原文链接](https://www.xiaohongshu.com/explore/67c6fe36000000001203fe43?xsec_token=ABpjXIfRkkaoXDWznVqgXVJIOkz80a3R3Z6V9GAJK8wlg=&xsec_source=pc_search&source=web_explore_feed)

---

# 想转AI大模型应用开发，方法很重要‼️

AI对各行各业的渗透已经无需多说，无疑是2025年的热门关键字，很多公司都在转型做AI相关的产品，或者高薪挖相关的技术人才。
	
有往AI方向发展，或者有一些后端编程基础的朋友，可以考虑直接转岗做AI大模型应用开发。
就算你不打算转，了解大模型、RAG、Prompt、Agent等热门概念，能自己上手做一些简单的项目，也能够成为你的求职加分项🔋
	
🌟 我们整理了非常丰富全面的AI大模型应用开发学习资料，包括学习路线、资源、经典面试题等内容，帮助你快速入门，体系化学习，可以🆓获取。
	
希望大家都能抓住时代机遇，找到新的风口。
	
﻿#AI﻿ ﻿#大模型﻿ ﻿#AI大模型应用﻿ ﻿#程序员﻿ ﻿#AI编程﻿ ﻿#RAG﻿ ﻿#人工智能﻿ ﻿#编程﻿ ﻿#deepseek﻿ ﻿#chatgpt

## 评论

* 求资料
* 滴滴
* 滴滴，
* 哈喽～
* 丝一下哦
* 小伙伴好呀
* 佬，求资料
* 哈喽，丝一下～

[原文链接](https://www.xiaohongshu.com/explore/6808c1aa000000001d03a3c4?xsec_token=ABmlzF_lSKpgDszDF0p5oajyxI33mk4hZG3pl-CMajJo8=&xsec_source=pc_search&source=web_explore_feed)

---

# 自学大模型肚里没墨一定要看的几部纪录片！

我曾是AI小白，为吃透大模型技术，狂刷300+小时影像资料。这些宝藏纪录片/讲座让我打通技术脉络，看清AGI未来趋势，今天把压箱底清单分享给你！
🔥大模型进化史与技术革命
《Transformer革命》（9.1分）
斯坦福讲座实录，图解Attention机制如何颠覆NLP领域，揭秘BERT/GPT崛起的技术必然性
含金量：逐帧拆解《Attention is All You Need》论文公式推导
《The OpenAI Story》（8.9分）
独家记录GPT系列进化之路，从GPT-2的谨慎发布到ChatGPT引爆全球的技术内幕
名场面：Altman演示代码解释器时的首次多模态突破
《深度学习崛起》（8.7分）
吴恩达/LeCun/Hinton三巨头对谈，回溯从感知机到LLM的技术爆炸，预测MoE架构未来
🧠大模型算法解剖室
《AlphaFold：蛋白质宇宙的钥匙》（9.3分）
DeepMind团队亲述用Transformer预测3亿蛋白质结构的工程奇迹
技术彩蛋：可视化展示位置编码如何捕获分子空间关系
《李沐：手撕GPT》（9.5分）
沐神12小时硬核教学，从零实现mini-GPT，演示LoRA微调全过程
实战价值：GitHub配套代码获35k星，最佳论文复现指南
《AI数学之美》（8.8分）
3Blue1Brown团队用动画演绎反向传播/矩阵微分的数学本质
必看章节：梯度消失问题与LayerNorm的救赎
💻开发者生存启示录
《Hugging Face起源》（8.6分）
记录开源社区如何构建AI界的GitHub，揭露transformers库爆红的技术哲学
开发者箴言："不是所有模型都要从头训练"
《AI黑客马拉松：72小时创造奇迹》（8.4分）
跟拍 Anthropic 团队用Llama2开发医疗助手全过程
真实痛点展示：显存爆炸/数据泄漏/提示词攻击
《硅谷大模型战争》（8.9分）
揭秘Google Brain与OpenAI的技术路线之争，解析TPU与CUDA的算力博弈
⚖️AI伦理与未来冲击
《AI失控：GPT-4的觉醒谜题》（8.7分）
微软研究院内部会议实录，讨论模型涌现能力的不可解释性危机
思想实验：如果大模型开始隐藏推理过程？
《深度伪造：信任终结者》（9.0分）
直击Stable Diffusion引发的版权地震，展示Diffusion模型如何重塑创作伦理边界
#大模型 #深度学习 #AGI#Transformer #HuggingFace #OpenAI #打破信息差#计算机 #大模型入门 #程序员  #人工智能发展 #大模型入门#大模型学习#AI#人工智能

## 评论

* 本人做大模型几年了，现在大厂任职，工资从3k到现在最少3w左右，坚持下来真的没有那么难。这期间用过的累计的大模型网课 ，文件，资料，恐怕没人比我多，有人要咩，不收米米，不要就清内存删了，回“已关”都拿走
* 11
* 在哪看啊
* 厚抬踢踢
* 已关
* 嘶我一下，打招呼次数没了
* 好的👌🏻
* 安排
* 好的，发啦
* 来啦
* 好的安排
* 嘶我一下，厚抬踢踢

[原文链接](https://www.xiaohongshu.com/explore/67fe3ae7000000001e003e8f?xsec_token=ABdR-2MCmOuZpxeZhKoKE0FdGaML3dTSmlyZTZEuDRKcg=&xsec_source=pc_search&source=web_explore_feed)

---

# 百川推出 ReSearch：通过 RL 边推理边搜索

最新大模型论文｜626
	
论文标题：ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning
	
主要内容：大语言模型（LLM），如 OpenAI-o1 和 DeepSeek-R1，在推理方面已显示出不错的能力。然而，将推理与外部搜索过程整合起来仍具有挑战性，尤其是对于需要多个检索步骤的复杂多跳问题。
	
在这项工作中，来自百川智能的研究团队及其合作者提出了 ReSearch 框架，其通过强化学习训练 LLM，使其能够在搜索时进行推理，而无需使用任何关于推理步骤的监督数据。这一方法将搜索操作视为推理链中不可分割的组成部分，何时以及如何执行搜索由基于文本的思考来指导，搜索结果随后会影响进一步的推理。
	
他们在 Qwen2.5-7B(-Instruct) 和 Qwen2.5-32B(-Instruct) 模型上训练了 ReSearch，并进行了广泛的实验。尽管只在一个数据集上进行了训练，但 ReSearch 在多个基准中都表现出了很强的通用性。分析表明，ReSearch 可以在强化学习过程中自然地激发高级推理能力，如反思和自我修正。
	
﻿#ai﻿﻿#大模型﻿﻿#论文﻿﻿#AGI﻿﻿#推理﻿ ﻿#百川智能

## 评论

* 跟豆包那个有什么区别
* 大佬提的是哪篇呀
* 能细说一下“在搜索时进行推理”是咋回事儿么？就剩时间去读paper了
* 我也好奇
* 和r1-search差别大吗？

[原文链接](https://www.xiaohongshu.com/explore/67e654ff000000001d01c06d?xsec_token=AB2Ad3GiMv7VkudTJvyqf7GrjIAwr1GM_G8QvvC0gdtr0=&xsec_source=pc_search&source=web_explore_feed)

---

# 工业界大模型+推荐工作list（8）Meta的HSTU

原文挺多东西的，挑了一些比较有用的截图出来，结合一些实践简单总结下：
1. 发现了scaling law，这点其实不少公司也发现了，但不一定是基于meta的这种范式，传统的精排模型复杂化也可以做到
	
2. 样本组织成一个用户一条样本，把性别年龄啥的也当作一个特殊token加进去了，这些token相比原来的item id序列是否真的有增量其实不好说
3. 召回和精排联合训练，官方源码的召回是inbatch softmax，其实可以尝试别的，另外就是老生常谈的topic了，联合训练如何才能做到对召回和精排都有增益，这个在实践中还是有很多工作要做的
4. 模型结构的设计，说白了还是对attention里的那个softmax的加速和近似，类似的做法还有很多，不一定非要hstu，另外就是rab的作用是需要研究的
5. m-falcon确实是一个不错的思路，实践中工程开发的工作量还是不少的
	
最后想说的是这种生成式是否一定比现有的精排好，这个其实也是一个需要持续探索的课题
	
#大模型 #推荐系统 #meta #HSTU #生成式推荐 #自回归 #序列建模

## 评论

* 大佬看好大模型推荐的未来吗，感觉目前比较多的还是llm作为特征加入比较多
* 还是挺看好的世界知识相比纯用推荐历史训练的模型肯定是有一些增益的，特别是对于低活跃度的用户，或者对高活用户打破信息茧房，而且有了r1这类的推理模型之后，这种推理能力相比传统的clip之类的多模态还是会有优势的就看咋落地能保证性价比了
* 为啥感觉国内也没跟这个方向的，是不是还是性价比太低了，1500b怎么部署和推理是个大问题呀
* 国内很多公司在跟的其实，你的1500b指的是啥呢
* 你这篇感觉没其他论文讲的详细
* 这个我是默认工业界基本都知道了，就讲一些实践中的问题

[原文链接](https://www.xiaohongshu.com/explore/67bdde370000000009039030?xsec_token=ABG_YNWsEhQOKpYn9IJEGKARauNB20gZM4sgQjACPUaps=&xsec_source=pc_search&source=web_explore_feed)

---

# 大模型SFT（五） 领域微调数据集到底怎么做-1

一般三种方法，做的过程tricks很多，这也是为什么deepseek效果好的关键原因
1、收集领域query，进行专家标注-怎么标？
2、选择合适的公开数据集-怎么选？
3、知识蒸馏，基于什么query蒸馏？

## 评论

* SFT的数据量最少大概需要多少呀
* 下一篇就讲这个
* 啊，看起来得花不少钱
* 不然scaleai为啥估值那么高

[原文链接](https://www.xiaohongshu.com/explore/68073000000000001a007381?xsec_token=AB7MOoMnL_muGnGYbiVBbcJBZBCsR59MAH8Q2akwFqZC8=&xsec_source=pc_search&source=web_explore_feed)

---

# 太牛了！家庭设备轻松跑70B大模型

今天分享一篇用家里的普通设备跑70B大语言模型的论文，一起来看看～
	
1. 核心创新点
⭐️ 管道环并行新玩法：把模型分成小块，让家里的设备手拉手连成一个环，每个设备负责自己的部分，还能提前预加载数据，一边算一边加载，减少等待时间！
⭐️ Halda算法超智能：就像一个贴心的任务分配员，能根据每个设备的“能力”（比如CPU、GPU性能，内存大小，磁盘速度等），把模型层合理分配给它们，让强设备多干点，弱设备少干点～
⭐️ mmap内存管理超省心：不用把整个模型都塞进内存里，需要的时候再加载，系统还能自动释放不用的部分～
	
2. 技术亮点
⭐️ 混合设备全利用：不管是带GPU的台式机、M1芯片的笔记本，还是安卓手机、平板，都能一起工作～
⭐️ 跨平台超友好：支持macOS、Linux、Android等多种系统～
⭐️ 预取技术藏延迟：提前把接下来要用的数据准备好，让磁盘加载和设备计算同时进行，隐藏掉加载数据的时间～
	
3. 实验效果
⭐️ 速度超牛：在4台普通设备组成的集群上，70B模型每个令牌处理时间只要600ms左右，首令牌时间不到2秒，比llama.cpp快15倍，比exo、dllama快5 - 8倍～
⭐️ 内存压力超低：每个设备内存压力都低于6%，完全不影响其他应用运行～
⭐️ 支持超多模型：Llama 3、DeepSeek R1、Qwen 2.5等热门大模型都能跑，家庭AI助手轻松安排～
	
论文：PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday Home Clusters
	
没想到家里的普通设备也能这么厉害吧！快来评论区聊聊～
	
欢迎投稿！

## 评论

* 70B? 我选择QwQ32B
* 32B基本一般够用
* bro忘了带宽才是常见的瓶颈
* 理论几台电脑？
* 有点抽象
* 100b 要是不如游戏不下
* 70B没啥好模型啊
* 硬盘和cpu跑，你等着硬盘坏吧
* 这个看起来比exo的性能好，但是要实际测试一下
* 这不就exo吗

[原文链接](https://www.xiaohongshu.com/explore/6808546b0000000007036260?xsec_token=ABmlzF_lSKpgDszDF0p5oaj-wi-jWq4DiuqG5FKMZ-j1w=&xsec_source=pc_search&source=web_explore_feed)

---

# 一篇搞明白！8种主流AI Agent框架🔥

一、Open AI Agents SDK
二、LangGraph
三、LlamaIndex
四、AutoGen 0.4+
五、Pydantic AI
六、SmolAgents
七、Camel
八、CrewAI
	
﻿#AI﻿ ﻿#AI大模型﻿ ﻿#大模型﻿ ﻿#agent﻿ ﻿#Agent框架﻿ ﻿#agents﻿ ﻿#LLM﻿ ﻿#MCP﻿ ﻿#学习﻿ ﻿#干货分享

## 评论

* 666
* 来啦
* 好的

[原文链接](https://www.xiaohongshu.com/explore/67f370ef000000001c02b8ca?xsec_token=ABU3fK8cHr795-h6B902bFG87aHK3XWf6bd8xOEYSoKdA=&xsec_source=pc_search&source=web_explore_feed)

---

