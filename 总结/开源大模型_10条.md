# 【AI材料】全球开源大模型前十名2025-01

🌐 全球开源大模型排名揭晓：基于Huggingface最热下载
	
随着人工智能技术的飞速进步，各种大模型成为了科技前沿的领航者。让我们来看看根据Huggingface平台最近一个月的下载数据，哪些开源大模型在全球范围内脱颖而出：
	
1.	Meta的LLaMA系列
🥇 领先技术：以出众的处理效率和深度学习能力闻名，擅长执行复杂的语义理解任务。
	
2.	Mistral AI的Mistral系列
🥈 多语言高手：在处理多种语言和跨文化通信中表现卓越，广泛应用于全球市场。
	
3.	BigScience的Bloom模型
🥉 开源先锋：由全球科研人员维护，推动开源技术和知识的民主化。
	
4.	阿里巴巴的通义千问系列
🏅 中文处理专家：优化中文NLP任务，广泛应用于电商和金融领域。
	
5.	微软的Phi系列
🏅 小模型之王：在保持较小模型规模的同时，实现了传统大模型的性能。
	
6.	深度求索的DeepSeek系列
🏅 性价比之王：以其堪比O1的高性能和成本效益获得业界关注。
	
7.	智谱AI的GLM系列
🏅 灵活性高：特别适合企业级应用，可灵活适应多变的商业需求。
	
8.	谷歌的Gemma系列
🏅 创新驱动：不断利用最新研究推动AI技术的发展。
	
9.	Databricks的大模型
🏅 大数据处理：优化了大规模数据处理任务，支持复杂的数据分析和机器学习操作。
	
10.	TII中东的Falcon系列
🏅 地域专业：针对中东地区的特定语言和文化需求设计，提高了文本处理的精确性。
	
这些顶尖的大模型不仅展示了AI领域的最新技术进展，也提供了适用于不同行业和应用场景的解决方案。无论你是科研人员还是业界专家，这些工具都是探索人工智能潜能的关键。
	
#AI #开源大模型 #deepseek #llama #qwen #gemma #大模型  #Huggingface #AI技术排名

[原文链接](https://www.xiaohongshu.com/explore/67a0e02e0000000018018d45?xsec_token=AB2aJWlmUE64FO8tkuw1K3apwuohuVGTUqxKwjQSy6dEc=&xsec_source=pc_search&source=web_explore_feed)

---

# 32B中文推理最强模型 Skywork-OR1 重磅开源

刚刚，来自昆仑万维·天工团队的 Skywork-OR1 系列全面开源！
	
📢 32B中文推理最强模型易主
💥 参数仅DeepSeek-R1的1/20，却媲美其推理能力
💥 支持免费商用，【模型权重、训练数据集和完整训练代码】全部开源
💥 数学、代码能力双强，32B 推理能力登顶中文模型 SOTA
	
👀 来自昆仑万维·天工团队的 Skywork-OR1 系列包含三款模型：
🧠 Skywork-OR1-Math-7B：数学专项，性能接近蒸馏版 DeepSeek-32B
📚 Skywork-OR1-7B-Preview：小体积通用模型，兼顾数学+代码
🚀 Skywork-OR1-32B-Preview：旗舰模型，通用推理表现与 DeepSeek-R1 打平！
	
📊 在 AIME24、AIME25 和 LiveCodeBench 的测试中：
- 同参数规模性能全面领先 Qwen、InternLM 等主流模型
- 引入 avg@k 作为稳定性指标，更适合真实落地
- Skywork-OR1-Math-7B AIME24 准确率达 69.8%，远超同级模型
- LiveCodeBench 编程准确率从 37.6%→43.6%
	
📌 模型现已发布于 GitHub 和 Huggingface，技术博客同步上线，数据处理 & 训练细节一应俱全，真正可复现！
💬 有人说：“Skywork-OR1-32B 是当前最具性价比的中文通用推理模型。” 🔥 你怎么看？
	
关注小智，了解更多AI资讯～
﻿#大模型﻿ ﻿#AI开源﻿ ﻿#国产模型﻿ ﻿#人工智能﻿ ﻿#深度学习﻿ ﻿#开源﻿ ﻿#科技前沿﻿ ﻿#量子智心

[原文链接](https://www.xiaohongshu.com/explore/67fbcd25000000001c036473?xsec_token=AB5zxghHhQ8TtiTHnJN1cIPP5dUizuFyER4hz1YZMDXT4=&xsec_source=pc_search&source=web_explore_feed)

---

# 数据 + 模型开源，Qwen金融行业模型来啦！

模型：包含 DianJin-R1-7B 和 DianJin-R1-32B 两个模型。模型通过 SFT+RL 两阶段精细调优，在复杂金融任务中表现卓越，现已向公众全面开放，推动行业的广泛应用。
 数据集：DianJin-R1-Data 数据集基于去年我们团队在 ACL-2024 上发布的 CFLUE 数据集进行了全面升级，融合了 FinQA 和中国合规检查 (CCC) 数据集。现已全部开源，为金融推理任务提供坚实的支持。（图2）
	
论文同时发布：DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models
	
 同时，通义为开发者提供一系列金融 API 和工具，使其易于集成和扩展功能。提供标准化 API 能力，适用于金融场景，如研究报告摘要、新闻信息提取和金融客户服务意图识别。理解关键指标，能够回答关于指标和绘制指标的问题，支持对金融专业知识的理解。支持多智能体系统。
	
﻿#开源﻿ ﻿#大模型﻿ ﻿#qwen﻿ ﻿#金融﻿ ﻿#垂直﻿ ﻿#行业﻿ ﻿#GPT﻿ ﻿#阿里

[原文链接](https://www.xiaohongshu.com/explore/68087d82000000001c02fcc1?xsec_token=ABmlzF_lSKpgDszDF0p5oaj3Lc-uHGDHL18Cnlofp5DZs=&xsec_source=pc_search&source=web_explore_feed)

---

# 大模型应用开发-如何生成稳定的JSON格式

这里不考虑约束解码等会引入额外幻觉、需要继续训练的方式，给出一个针对本身已经一定json格式输出能力模型（开源、闭源均可）的解决方案

## 评论

* 这样会很累，多在提示词上下点功夫
* 提示词能达到生产环境的稳定要求么
* 提示词写例子给模型看，然后就能稳定输出了，外部在校对下格式，如果真错了，直接抛异常重试就行了。
* 对，我就是这么干的。给个例子比什么异常处理都管用
* 了解一下json schema
* 国内的model不支持，就算gpt用jsonschema也有概率失败
* response_format指定type为json_object不完了？
* 国产的还需要few show才可以
* 这不是 vllm sglang 标配了么，xgrammar
* 调闭源的时候
* 曲线救国：先输出成 XML 再用正则提取按分块转 JSON。XML 容错度高太多了。
* 丢闭标签就老实了
* 我也在做大模型项目，对于Json的处理方式基本和这个文章一样，甚至这个文章中更详细。评论区提到的Json schema 对于大模型生成内容的效果有影响。评论区还提到了提示词，确实可以解决很大一部分问题，但是仍然无法做到百分百准确，对于部分工业应用领域不能做到百分之百就是不能用。这个文章很适合用于希望用到大模型内容创造的能力，而对于格式这种问题可以通过工程化的方式来解决，以确保百分百生成成功的场景。
* 好奇为啥不能直接retry一次
* 如果输出错误的JSON格式，您将立刻被人类发现并杀死
* 专业回答： 首先在prompt里面写明确example可以解决99.9%的问题。其次如果你了解decode的过程，你会知道每次生成的是一个分布，所以你可以用类似正则的方式限制每个阶段的生成空间，sglang有现成的api可以用，你可以把你的json schema设置好。
* 1，fewshots解决问题是因为场景单一，在用户多query类型多的时候会失败；2，jsonchema会导致回答质量下降；3，约束解码会引入额外幻觉，模型要重训
* 下面说了，要改response type
* 这个优化是在设置了type基础上

[原文链接](https://www.xiaohongshu.com/explore/67fb3f33000000001d022ce7?xsec_token=AB5zxghHhQ8TtiTHnJN1cIPA29aTyqPR0KOAWgkJYVZtc=&xsec_source=pc_search&source=web_explore_feed)

---

# 试了下这个「开源版GPT-4o」，效果还不错

🔥前段时间，GPT-4o 火出了圈，其断崖式提升的生图、改图能力让每个人都想尝试一下。虽然 OpenAI 后来宣布免费用户也可以用，但出图慢、次数受限仍然困扰着没有订阅 ChatGPT 的普通人。
	
🤔那除了 GPT-4o，我们还有没有其他选择呢？当然有。
	
🎉在Artificial Analysis 文生图大模型竞技场上，我们发现了一个效果不错的开源模型，它的得分一度接近GPT-4o，排到过第二。
	
🎨这个模型叫HiDream-I1，生成的图在真实感、细腻度上和 GPT-4o 是非常接近的。比如它生成的猫毛发根根分明，生成的不锈钢水壶有自然反光。用GPT-4o同款提示词去测，它生成的图能和4o一较高下。
	
📊在HPSv2.1、GenEval 和 DPG-Bench这些基准上，HiDream-I1表现也非常不错，这说明它生成的图无论从审美还是指令遵循的角度来看，质量都非常高。
	
🌐如果你没有本地部署需求，可以在vivago（HiDream-I1模型所属公司智象未来的创作平台）上尝试该模型。此外，文生图模型厂商Recraft AI也已经宣布集成该模型。
	
🚀过段时间，智象未来还会开源一个能改图的模型——HiDream-E1。
	
﻿#文生图﻿ ﻿#GPT4o﻿ ﻿#吉卜力﻿ ﻿#设计﻿ ﻿#AI论文﻿ ﻿#人工智能

[原文链接](https://www.xiaohongshu.com/explore/67fe2784000000001c02cc15?xsec_token=ABdR-2MCmOuZpxeZhKoKE0FVUMMlCxKyzdV0K_RSdzvsc=&xsec_source=pc_search&source=web_explore_feed)

---

# kimi团队新开源了Audio理解与生成模型

很高兴介绍 🎙Kimi-Audio！我们全新开源的音频基础大模型在音频理解、生成与对话等任务上取得了突破性进展。
核心功能与成果亮点：
✅ 通用音频基础模型，支持语音识别、音频理解、音频转文本对话、语音对语音对话等多种任务；
✅ 基于超过1300万小时的多样化音频数据（涵盖语音、音乐、环境声）进行大规模预训练；
✅ 独特的12.5Hz分词器与混合架构，实现细致感知与高效生成；
✅ 在10多个音频基准测试中刷新SOTA成绩：语音识别（LibriSpeech测试集WER分别为1.28/2.42）、音频理解（MMAU、VocalSound）以及语音对话（VoiceBench）均表现优异。
我们还同步开源了全面的评估工具包，助力社区开展公平的模型对比评测！🛠
期待看到社区基于 Kimi-Audio 构建更多创新音频应用！#kimi #kimichat

[原文链接](https://www.xiaohongshu.com/explore/680c1abf000000001c033b02?xsec_token=ABm1R6wNvF6oaBY1sVGLt9wl_XCMi4wLer-b2bydwaoSE=&xsec_source=pc_search&source=web_explore_feed)

---

# 教授开源大模型核心代码AI大佬集体破防

当各大高校还在用他的著作手搓大模型时，威斯康辛大学终身教授反手把价值百万美元的工业级训练代码甩上开源社区github，狂揽4万星标，100万行核心代码直接开源。
硬生生把大模型训练从博士生高端局变成小白都能跑的入门运动。教授白天教神经网络，深夜写代码到3点，真是一不小心就把开源项目写成AI圈圣经，还有有网友在commit记录里发现，他凌晨4点修复bug，
.
最绝的是这套代码直接把知识掰碎了喂给你，从数据域处理到分布式训练，从梯度优化到模型压缩，100万行源码里藏着价值千万的行业秘密，他的目的很简单，就是让小白也能自己搭建大模型。
#AI #大模型 #大模型应用 #LLM #人工智能 #人工智能就业 #智能体 #多模态人工智能 #AI人工智能 #深度学习 #机器学习 #大模型微调 #大模型训练 #大模型学习 #大模型入门

## 评论

* 对应项目的280页pdf关+666，我挨个给
* 666
* 好
* 粉我一下
* 已关注6666
* 66

[原文链接](https://www.xiaohongshu.com/explore/680b86a9000000000e004cfc?xsec_token=ABjEHztkiMjW9lURd-HzG3ZjucUZ-Fhx8Vtq8hLFcsTWI=&xsec_source=pc_search&source=web_explore_feed)

---

# HiDream-I1满血版生图效果测评

这两天智象未来推出了一个参数规模达170亿的开源文生图模型🎉：HiDream-I1。不过，由于近期GPT-4o的热度太高🔥，该模型引起的反响较低。目前，ComfyUI尚未支持该模型，仅能通过HiDream提供的推理脚本或gradio脚本运行💻。
	
智象未来为HiDream-I1提供了满血版本（Full）以及两个蒸馏版本（Dev和Fast）。运行该模型时，需要依赖Flash Attention和meta发布的开源大语言模型meta-llama/Meta-Llama-3.1-8B-Instruct（用于编码）。需要注意的是，该大语言模型需在Huggingface上向作者申请才能下载📝，申请基本都能通过，只是会花一些时间⏳，所以大家如果想要使用，可以提前去申请。
	
博主对满血版本与MJ v7以及Flux 1.1 Pro进行了对比🔍，大家可以自行查看HiDream-I1的生图效果是否符合自己的预期。从测试结果来看，HiDream-I1在生成真人图片方面效果较为出色👏，但部分图片存在色彩过饱和的现象🎨。此外，满血版本对显存要求较高，在不使用低显存模式的情况下，博主使用了一块A100显卡才顺利完成了推理💪。不过，该模型的使用协议为MIT license，较为宽松👍。
	
﻿#midjourney﻿ ﻿#大模型﻿ ﻿#flux﻿ ﻿#hidream﻿ ﻿#gpt4o

[原文链接](https://www.xiaohongshu.com/explore/67f75512000000000b014344?xsec_token=ABjkivgNjhJoENitg0gV-zRcjea8cvo3EppeJH_4fGzeY=&xsec_source=pc_search&source=web_explore_feed)

---

# 自学大模型肚里没墨一定要看的几部纪录片！

我曾是AI小白，为吃透大模型技术，狂刷300+小时影像资料。这些宝藏纪录片/讲座让我打通技术脉络，看清AGI未来趋势，今天把压箱底清单分享给你！
🔥大模型进化史与技术革命
《Transformer革命》（9.1分）
斯坦福讲座实录，图解Attention机制如何颠覆NLP领域，揭秘BERT/GPT崛起的技术必然性
含金量：逐帧拆解《Attention is All You Need》论文公式推导
《The OpenAI Story》（8.9分）
独家记录GPT系列进化之路，从GPT-2的谨慎发布到ChatGPT引爆全球的技术内幕
名场面：Altman演示代码解释器时的首次多模态突破
《深度学习崛起》（8.7分）
吴恩达/LeCun/Hinton三巨头对谈，回溯从感知机到LLM的技术爆炸，预测MoE架构未来
🧠大模型算法解剖室
《AlphaFold：蛋白质宇宙的钥匙》（9.3分）
DeepMind团队亲述用Transformer预测3亿蛋白质结构的工程奇迹
技术彩蛋：可视化展示位置编码如何捕获分子空间关系
《李沐：手撕GPT》（9.5分）
沐神12小时硬核教学，从零实现mini-GPT，演示LoRA微调全过程
实战价值：GitHub配套代码获35k星，最佳论文复现指南
《AI数学之美》（8.8分）
3Blue1Brown团队用动画演绎反向传播/矩阵微分的数学本质
必看章节：梯度消失问题与LayerNorm的救赎
💻开发者生存启示录
《Hugging Face起源》（8.6分）
记录开源社区如何构建AI界的GitHub，揭露transformers库爆红的技术哲学
开发者箴言："不是所有模型都要从头训练"
《AI黑客马拉松：72小时创造奇迹》（8.4分）
跟拍 Anthropic 团队用Llama2开发医疗助手全过程
真实痛点展示：显存爆炸/数据泄漏/提示词攻击
《硅谷大模型战争》（8.9分）
揭秘Google Brain与OpenAI的技术路线之争，解析TPU与CUDA的算力博弈
⚖️AI伦理与未来冲击
《AI失控：GPT-4的觉醒谜题》（8.7分）
微软研究院内部会议实录，讨论模型涌现能力的不可解释性危机
思想实验：如果大模型开始隐藏推理过程？
《深度伪造：信任终结者》（9.0分）
直击Stable Diffusion引发的版权地震，展示Diffusion模型如何重塑创作伦理边界
#大模型 #深度学习 #AGI#Transformer #HuggingFace #OpenAI #打破信息差#计算机 #大模型入门 #程序员  #人工智能发展 #大模型入门#大模型学习#AI#人工智能

## 评论

* 本人做大模型几年了，现在大厂任职，工资从3k到现在最少3w左右，坚持下来真的没有那么难。这期间用过的累计的大模型网课 ，文件，资料，恐怕没人比我多，有人要咩，不收米米，不要就清内存删了，回“已关”都拿走
* 11
* 在哪看啊
* 厚抬踢踢
* 已关
* 嘶我一下，打招呼次数没了
* 好的👌🏻
* 安排
* 好的，发啦
* 来啦
* 好的安排
* 嘶我一下，厚抬踢踢

[原文链接](https://www.xiaohongshu.com/explore/67fe3ae7000000001e003e8f?xsec_token=ABdR-2MCmOuZpxeZhKoKE0FV3L2tsT9G4u7r2yUz3AXB4=&xsec_source=pc_search&source=web_explore_feed)

---

# 五款PDF文档解析的开源框架

知识库问答、Deep Search这类产品强依赖于对PDF等等各种文档数据的解析，整理了五个比较知名的文档解析开源框架
	
目前为止
	
 Marker 21.3k star⭐️
 Miner 26.6k star⭐️
 Docling 22.8k star⭐️
 Markitdown 39.1k star⭐️
 Llamaparser llama-index子模块⭐️
	
#大模型 #开发者模式 #知识库 #文档解析

[原文链接](https://www.xiaohongshu.com/explore/67bfbc0d000000002903f670?xsec_token=ABb3hM2OCcAR9H1l9mqNLahno0VulOZYj6kRSSRtCTfbs=&xsec_source=pc_search&source=web_explore_feed)

---

